{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3486,"databundleVersionId":31310,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch \nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\n!pip install timm\nimport timm\nimport pandas as pd \nimport random\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNetModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.timm_model = timm.create_model('densenet201', pretrained=True, in_chans=1)\n        self.fc = nn.Linear(1000, 30)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.timm_model(x)\n        x = self.relu(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EfficientNetModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.timm_model = timm.create_model('tf_efficientnetv2_s', pretrained=True, in_chans=1)\n        self.fc = nn.Linear(1000, 30)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.timm_model(x)\n        x = self.relu(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MobileNetModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.timm_model = timm.create_model('mobilenetv3_large_100', pretrained=True, in_chans=1)\n        self.fc = nn.Linear(1000, 30)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.timm_model(x)\n        x = self.relu(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class InceptionNextModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.timm_model = timm.create_model('inception_next_small', pretrained=True, in_chans=1)\n        self.fc = nn.Linear(1000, 30)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.timm_model(x)\n        x = self.relu(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(data.Dataset):\n    def __init__(self, mode, images, targets=None):\n        super().__init__()\n        self.mode = mode\n        self.images = images\n        self.targets = targets\n    \n    def transform(self, image, target=None):\n        image = transforms.ToTensor()(image)\n        if self.mode == 'train':\n            p = random.random()\n            if p > 0.5:\n                image = transforms.GaussianBlur(5)(image)\n                           \n            p = random.random()\n            if p > 0.5:\n                mask = torch.rand(size=image.shape)\n                mask[mask > 0.95] = 0\n                mask[mask <= 0.95] = 1\n                image = mask * image\n\n            p = random.random()\n            if p > 0.5:  \n                angle = random.randint(-20, 20)\n                image = transforms.functional.rotate(image, angle=angle)\n                angle = -angle\n                idx = target == -1\n                angle_radians = math.radians(angle)\n                x = (target[::2] - 48) * math.cos(angle_radians) - (target[1::2] - 48) * math.sin(angle_radians)\n                y = (target[::2] - 48) * math.sin(angle_radians) + (target[1::2] - 48) * math.cos(angle_radians)\n                target[::2] = x + 48\n                target[1::2] = y + 48\n                target[idx] = -1\n\n        if self.mode == 'train' or self.mode == 'val':\n            return image, target\n        else:\n            return image\n        \n    def __getitem__(self, index):\n        if self.mode == 'train' or self.mode == 'val':\n            return self.transform(self.images[index], target=self.targets[index])\n        else:\n            return self.transform(self.images[index])\n\n    def __len__(self):\n        return self.images.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reshape_images(images):\n    images_reshaped = np.zeros((images.shape[0], 96, 96, 1))\n    for i, img in enumerate(images):\n        img = img.split(' ')\n        img = np.array([int(num) for num in img])\n        img = img.reshape((96, 96, 1))\n        images_reshaped[i] = img\n    \n    return images_reshaped\n        \nraw = pd.read_csv('/kaggle/input/facial-keypoints-detection/training.zip', compression='zip')\nraw = raw.sample(frac=1)\nfeatures_name = list(raw)   \nfeatures_name.remove('Image')\nimages = raw['Image']\ntargets = raw.drop(columns=['Image'])\ntargets = targets.fillna(-1).to_numpy()\n\ntrain_images = images[0: int(raw.shape[0] * 0.9)]\ntrain_targets = targets[0: int(raw.shape[0] * 0.9)]\ntrain_images = reshape_images(train_images)\n    \nval_images = images[int(raw.shape[0] * 0.999): ]\nval_targets = targets[int(raw.shape[0] * 0.999): ]\nval_images = reshape_images(val_images)\n\nraw = pd.read_csv('/kaggle/input/facial-keypoints-detection/test.zip', compression='zip')\ntest_images = raw['Image']\ntest_images = reshape_images(test_images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.MSELoss()\nbatch_size = 64\nlearning_rate = 0.001\nnum_epochs = 210\ndecay_every = 30\ndecay = 0.25","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = MyDataset('train', train_images, train_targets)\nval_dataset = MyDataset('val', val_images, val_targets)\ntest_dataset = MyDataset('test', test_images)\ntrain_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\ntest_loader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodels = [InceptionNextModel(), MobileNetModel(), DenseNetModel(), EfficientNetModel()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    all_epochs_train_loss = []\n    all_epochs_val_loss = []\n    model = model.to(device)\n    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1)\n    scheduler = StepLR(optimizer, decay_every, gamma=decay)\n    for epoch in range(1, num_epochs + 1):\n        print('epoch:', epoch)\n        model.train()\n        for samples, targets in train_loader:\n            samples = samples.to(device).float()\n            targets = targets.to(device).float()\n            preds = model(samples)\n            idx = targets == -1\n            preds[idx] = -1\n            loss = loss_func(preds, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step() \n\n        scheduler.step()\n        model.eval() \n        with torch.no_grad():\n            for mode, loader in zip(['train', 'val'], [train_loader, val_loader]):\n                epoch_loss, num_samples = 0, 0\n                for samples, targets in loader:\n                    samples = samples.to(device).float()\n                    targets = targets.to(device).float()\n                    preds = model(samples)\n                    idx = targets == -1\n                    preds[idx] = -1\n                    loss = loss_func(preds, targets)\n                    epoch_loss += loss.item() * targets.shape[0] \n                    num_samples += targets.shape[0]\n\n                epoch_loss = np.sqrt(epoch_loss / num_samples)\n                if mode == 'train':\n                    all_epochs_train_loss.append(epoch_loss)\n                else:\n                    all_epochs_val_loss.append(epoch_loss)\n                print(mode, '- loss:', f'{epoch_loss:.4}')\n            \n    plt.plot(np.arange(num_epochs), all_epochs_train_loss, np.arange(num_epochs), all_epochs_val_loss)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_locs = []\nfor model in models:\n    loc = []\n    model.eval() \n    with torch.no_grad():\n        for samples in test_loader:\n            samples = samples.to(device).float()\n            preds = model(samples)\n            loc = loc + preds.flatten().tolist()\n    \n    all_locs.append(loc)\n\nloc = np.array(all_locs).mean(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'ImageId': np.array([[i] * 30 for i in range(1, 1784)]).flatten(),\n                   'FeatureName': features_name * 1783,\n                   'Location': loc})\nsample_sub = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')\npreds = df.merge(sample_sub, on=['ImageId', 'FeatureName'])['Location_x']\nsub = pd.read_csv('/kaggle/input/facial-keypoints-detection/SampleSubmission.csv')\nsub['Location'] = preds\nsub.to_csv('submission.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}